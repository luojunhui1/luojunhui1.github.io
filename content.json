{"pages":[{"title":"关于","text":"我是谁？ 西南交通大学信息科学与技术学院计算机专业学生 罗俊辉 西南交通大学学生会 青年之声工作站前部长 西南交通大学 ROBOMASTER Heilos 战队视觉组成员 我会啥？ 简单的C++ 简单的Matlab 简单的Python 简单的视觉处理 不会算法 联系我？ QQ: 2479694366","link":"/About/index.html"}],"posts":[{"title":"欢迎来到我的博客","text":"","link":"/index/"},{"title":"Image Preprocessing","text":"噪声处理一般而言，我们将噪声分为以下几类 噪声类别 椒盐噪声 加性噪声 乘性噪声 高斯噪声 椒盐噪声也称为脉冲噪声，是图像中经常见到的一种噪声，它是一种随机出现的白点或者黑点，可能是亮的区域有黑色像素或是在暗的区域有白色像素（或是两者皆有）。 加性噪声一般指热噪声、散弹噪声等，它们与信号的关系是相加，不管有没有信号，噪声都存在。 而乘性噪声一般由信道不理想引起，它们与信号的关系是相乘，信号在它在，信号不在他也就不在。 图像去噪的方法有很多种，其中均值滤波、中值滤波、高斯滤波等比较基础且成熟，还有一些基于数学中偏微分方程的去噪方法，基于频域的小波去噪方法。中值滤波，均值滤波以其快速、稳定的特性，应用最为广泛，在OpenCV库中也直接提供了方法。 滤波的计算原理也比较容易理解，这里就不做过多介绍，放上一张效果图说明即可。 实际上，对于噪声的去噪处理实际上很多时候是一种模糊处理，这点从OpenCV中函数的命名就可以看出来，去噪让图片更平滑之外，也损失了一些信息，不过我们一般认为损失的信息无足轻重，而平滑更利于之后的特征提取等操作。 图像增强图像增强有以下两类： 图像增强方法 频域法 空间域法 频域法， 顾名思义，频域法就是把图像从空间域利用傅立叶、小波变换等算法把图像从空间域转化成频域，也就是把图像矩阵转化成二维信号，进而使用高通滤波或低通滤波器对信号进行过滤。采用低通滤波器（即只让低频信号通过）法，可去掉图中的噪声；采用高通滤波法，则可增强边缘等高频信号，使模糊的图片变得清晰。 空间域方法主要包括以下两种常用方法： 空间域方法 直方图均衡化 滤波 关于直方图均衡化能增强图像的原理，在博客 https://blog.csdn.net/weixin_38705903/article/details/88584181 中有详细说明。 基于滤波的方法主要有： 滤波 均值滤波 中值滤波 高斯滤波 图像分割图像分割是把图像分成若干个独立子区域的技术和过程，在计算机视觉的应用，我们关注的可以粗略的分为目标和前景，他们对应图像中特定的、具有独特性质的区域。为分割目标，我们需要将这些区域提取出来，这样才能进行如特征提取、目标识别等进一步的操作。 图像分割可分为这两个类别： 类别 非语义分割 语义分割 非语义分割分为以下几种类别： 非语义分割技术 说明 阈值分割 例如OpenCV中的二值化函数 区域分割 代表性的算法有两种：区域生长和区域分裂合并 聚类 利用样本的相似性，把相似的像素点聚合成同一个子区域 边缘分割 图像在边缘处灰度级会发生突变来对图像进行分割 直方图 通过统计图像中的像素，得到图像的灰度直方图，然后在直方图的波峰和波谷是用于定位图像中的簇 水平集 这个比较复杂，会额外写博客解释 区域生长代码如下： 12345678910111213141516171819202122232425262728293031323334353637383940cv::Mat MainWindow::regionGrowFast(const cv::Mat &amp;src, const cv::Point2i seed, int throld){ //convert src to gray for getting gray value of every pixel cv::Mat gray; cv::cvtColor(src,gray, cv::COLOR_RGB2GRAY); // set every pixel to black cv::Mat result = cv::Mat::zeros(src.size(), CV_8UC1); if((seed.x &lt; 0) || (seed.y &lt; 0)) return result; result.at&lt;uchar&gt;(seed.y, seed.x) = 255; //gray value of seed int seed_gray = gray.at&lt;uchar&gt;(seed.y, seed.x); //grow direction sequenc int grow_direction[8][2] = {{-1,-1}, {0,-1}, {1,-1}, {1,0}, {1,1}, {0,1}, {-1,1}, {-1,0}}; //seeds collection std::vector&lt;cv::Point2i&gt; seeds; seeds.push_back(seed); //start growing while(! seeds.empty()){ //get a seed cv::Point2i current_seed = seeds.back(); seeds.pop_back(); for(int i = 0; i &lt; 8; ++i){ cv::Point2i neighbor_seed(current_seed.x + grow_direction[i][0], current_seed.y + grow_direction[i][1]); //check wether in image if(neighbor_seed.x &lt; 0 || neighbor_seed.y &lt; 0 || neighbor_seed.x &gt; (gray.cols-1) || (neighbor_seed.y &gt; gray.rows -1)) continue; int value = gray.at&lt;uchar&gt;(neighbor_seed.y, neighbor_seed.x); if((result.at&lt;uchar&gt;(neighbor_seed.y, neighbor_seed.x) == 0) &amp;&amp; (abs(value - seed_gray) &lt;= throld)){ result.at&lt;uchar&gt;(neighbor_seed.y, neighbor_seed.x) = 255; seeds.push_back(neighbor_seed); } } } return result;} 区域分割代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869#include &lt;iostream&gt;#include &lt;opencv2/opencv.hpp&gt;#include &lt;opencv2/highgui/highgui.hpp&gt;#include &lt;opencv2/imgproc/imgproc.hpp&gt;#include &lt;Eigen/Core&gt;#include &lt;Eigen/Dense&gt;#include &lt;opencv2/core/eigen.hpp&gt;#include &lt;string&gt;#include &lt;cmath&gt;using namespace std;using namespace cv;using namespace Eigen;Mat src;Mat result;vector&lt;Rect&gt; rectToDepart;vector&lt;Rect&gt; resultRect;bool isDepart(Rect rect){ MatrixXf matrix; cv2eigen(src(rect), matrix); //cout &lt;&lt; matrix.mean() &lt;&lt;&quot;,&quot;&lt;&lt; rect.width&lt;&lt; &quot;,&quot;&lt;&lt;rect.height&lt;&lt;endl; MatrixXf averageRect = MatrixXf::Constant(rect.height, rect.width, matrix.mean()); MatrixXf subm = averageRect - matrix; long coff = ((subm.array() * subm.array()).sum()); if (coff &gt; 1000|| coff&lt;0)return true; return false;}bool Depart(Rect&amp; rect){ if (rect.width&lt;5||rect.height&lt;5 || !isDepart(rect)) { rectangle(result, rect, Scalar(255)); resultRect.push_back(rect); return false; } Mat cur = src(rect); int rectX = rect.x; int rectY = rect.y; int rectHalfWidth = (int)rect.width / 2; int rectHalfHeight = (int)rect.height / 2; rectToDepart.push_back(Rect(rectX, rectY, rectHalfWidth, rectHalfHeight)); rectToDepart.push_back(Rect(rectX + rectHalfWidth, rectY, rect.width - rectHalfWidth, rectHalfHeight)); rectToDepart.push_back(Rect(rectX, rectY + rectHalfHeight, rectHalfWidth, rect.height - rectHalfHeight)); rectToDepart.push_back(Rect(rectX + rectHalfWidth, rectY + rectHalfHeight, rect.width - rectHalfWidth, rect.height - rectHalfHeight)); return true;}int main(){ src = imread(&quot;1.jpg&quot;,IMREAD_GRAYSCALE); result = Mat(src.size(), CV_8UC1,Scalar(0)); Rect src_rect = Rect(0, 0, src.cols, src.rows); Rect cur_rect; Depart(src_rect); while (!rectToDepart.empty()) { cur_rect = rectToDepart.back(); rectToDepart.pop_back(); Depart(cur_rect); } while (1) { imshow(&quot;gray&quot;, src); imshow(&quot;depart&quot;, result); waitKey(30); } return 0;} 图像增广 图像增广（image augmentation）技术通过对训练图像做一系列随机改变，来产生相似但又不同的训练样本，从而扩大训练数据集的规模。图像增广的另一种解释是，随机改变训练样本可以降低模型对某些属性的依赖，从而提高模型的泛化能力。 目前常用的图像增广技术有如下几种： 图像增广技术 镜像变换 旋转 裁剪 平移 亮度修改 添加噪声 剪切 变换颜色 这些概念的理解比较简单，具体实现在OpenCV库中也有对应的函数可使用，就不详细说明，有兴趣的可以自行去其他地方查阅。","link":"/ImagePreprocessing/"},{"title":"C Plus","text":"","link":"/cplus_index/"},{"title":"数据库_并发","text":"事务并发的可串行化 事务的串行执行（serial execution）:DBMS按顺序一次执行一个事务，各个事务之间没有交错。 事务的并行执行（concurrent execution）:DBMS同时执行多个事务，DBMS对各事务的操作进行调度，另其交错执行。 事务并发执行的好处： 改善系统资源利用率 改善短事务响应时间 事务并发执行可能产生的问题： 多个事务同时存取数据库中统一数据可能会引起·数据的读写冲突，对数据库的一致性造成破坏。 调度的要求： 一个事务的操作在调度中的顺序应与它们在事务中的顺序一致。 事务如不加控制地并发执行，可能会产生以下三个问题： 不加控制的并发执行可能产生的问题 类型 丢失更新 写写冲突 读脏数据 写读冲突 读值不可复现 读写冲突 ​ 丢失更新图例 ​ 读脏数据图例 ​ 读值不可复现图例 由以上三个可能出现的问题得出结论： 把不同事物中对同一对象进行WW\\RW\\WR操作进行交错时都会造成冲突，因此，在安排事务的交错（并发执行）时，应避免将其放在一起。 并发执行的串行化准则 并发原则：既要交错执行，以充分利用系统资源，加快短事务响应时间，又要避免访问冲突。 事物调度原则：调度中，不同事务的操作可以交错，同一事务的操作需保持相对顺序不变。 可串行化的两个要点： 关心对数据库的读写操作 目的是研究如何形成一个可串行化的并发调度，即“等价于”一个串行调度的并发调度。 前趋图：前趋图是一有向图G=(V,E)，V为顶点集合，表示所有参与调度的事物，E可通过分析冲突操作来决定。以下是示例： 事务集：{T1, T2, T3, T4} S= $$W_{T3}(y)R_{T1}(x)R_{T2}(y)W_{T3}(x)W_{T2}(x)W_{T3}(z)R_{T4}(z)W_{T4}(x)$$ $$R_{T2}(y)$$与$$W_{T3}(y)$$有写读冲突（读脏数据），画一条由点T3指向T2的有向边。 $$W_{T2}(x)$$与$$R_{T1}(x)$$有读写冲突，画一条由点T1指向T3的有向边。 $$W_{T2}(x)$$与$$R_{T1}(x)$$和$$W_{T3}(x)$$分别有冲突，画一条由点T3指向T2的有向边和T1指向T2的有向边。 以此类推，最终得到图如下： 判断是否可串行化：若前趋图有回路，则不可串行化；若没有回路，则可以串行化。 寻找等价串行调度方法：先执行入度为0的节点（事务），再将该节点（事务）及其相连边从前趋图中删除，再寻找入读为0的节点（事务）执行，反复如此，直到事务全部执行完毕。 基于锁的并发控制在实际运用中，用前面提到的方法来先验事务的可串行化并生成对应的事务执行顺序是不现实的。主要原因有以下两点： 事务集随机，不固定 不可能实现定好调度 并发控制通常的实现方法：不关心具体的调度，由DBMS制定号=好一个协议，按此协议执行事务，即可保证事务的可串行化。 加锁协议（Locking Protocol）:是上面所说的协议的一种，利用加锁实现并发控制，即在操作前对操作对象加锁。 加锁协议类型 特性 X锁（排他锁） 可读可写，其他事物不可对被加锁的数据操作，直到X锁被释放。避免了所有类型的冲突，但降低了并发度。 两阶段加锁协议（2PL协议） 所有加锁都在释放锁之前。若所有事物都遵循该协议，则它们的任何调度都是可串行化的。 （S,X）锁 与X锁相比，多了一条S锁与S锁相容，提高了并发度。 （S,U,X）锁 数据对象加了U锁后仍可被加S锁，只在最后写入时，将U锁升级为X锁。相比于X（S,X）锁，又进一步提高了并发度。 多粒度加锁或封锁 数据对象的大小可以是一张表，也可以是一个元组。 级联回退：即一事务还未结束就把锁释放了，又由于其他原因，该事务需要回退，为避免其它事务督导脏数据，要求读了和对该数据更新的操作也回退。在X锁，（S,X）锁，（S,U,X）锁中均存在该问题。 加锁协议补丁1：为避免级联回退，不管是写操作锁还是读操作锁，都应该保持到事务结束才释放。该补丁对其后的加锁协议也适用。 活锁：在（S,X）锁中，若一个数据对象被加S锁，此时若有其它事务对其加S锁，则根据相容矩阵，应该被允许，此时若有事务欲对该数据加X锁，则此X锁会被不断推迟。 加锁协议补丁2：先申请先服务，避免活锁现象造成响应时间过长，影响体验。 粒度、控制和并发度的关系：粒度越大，控制越简单，并发度越低。 多粒度加锁-锁冲突检测问题： 显式加锁：自身被加锁 隐式加锁：上级被加锁 过程： 检查本身，有无显式锁与本事务显式锁冲突。 检查其所有祖先，以防本事务显式锁与其他事务隐式锁冲突。 检查其所有子孙，以防本事务隐式锁与其他事务显式锁冲突。 简化锁冲突的检测： 三种意向锁 意向共享锁（IS锁） 意向排他锁（IX锁） 加锁时，对祖先按自上而下的顺序加意向锁。 解锁时，按自下而上的次序解锁。 死锁检测与预防死锁：当事务出现循环等待时，若不加以干预，则会一直等待下去，形成死锁。 对付死锁的两个办法： 防止死锁 检测死锁，发现死锁后处理死锁。 预防死锁的方法： ​ 给每个事务以时间戳先后为准设立优先级，时间戳越前，事务优先级越高。若有A事务持有资源Z的锁，而B事务申请对Z的锁。若A优先级更高，则B等待；若B优先级更高，则A回滚，再重启事务A并继承A回滚前的时间戳。 检测死锁的方法： 超时法 等待图法 死锁处理的方法： 处理思想：杀死事务，打破循环等待 选择牺牲事务的标准： 选择最迟交付的 选择获得锁最少的 选择回退代价最小的 不同DBMS的标准可能不一样。 被杀死事务的处理方法： 告知用户事务因死锁被杀死，稍后再次向系统交付该事务 由DBMS重启该事务。 不管哪种处理方式，被杀死的事务都要等待一段时间才能被重新执行，否则可能会再次引起死锁。 附图","link":"/%E6%95%B0%E6%8D%AE%E5%BA%93-%E5%B9%B6%E5%8F%91/"},{"title":"水平集算法(level-set)","text":"显式轮廓法在说 level set 之前，我们先谈曲线的演变。假设我们现在有一条曲线如下，为知道这条曲线接下来的演化方向，我们需要知道这条曲线上每个点的运动方向和大小，这样就能确定曲线在下一时间点的轮廓。对于这条曲线来说，这可能并不难，但对于更加一般的情况来说，可能会出现以下几个问题： 显式轮廓法的缺陷 演化过程中轮廓可能需要插值增加轮廓点，或者减少轮廓点，实际应用比较麻烦 轮廓在演化过程中可能会出现分裂，合并的情况，而这在二维函数上难以处理 上面的这种方法很直观，但实现起来困难重重。为解决这两个问题，有人提出了隐式轮廓法。 隐式轮廓法隐函数为理解隐式轮廓法，首先要了解隐函数。我们要描述直线上的两个点，那么可以直接就写出两个点的坐标： 你也可以绕一下，写成集合的形式，也就是所谓的 level set： 这里的 y 的取值就是 level，那么和上面相比，直接是X 轴上的两个点。在这里的话，表达方式就成了，level 为1 的所有x取值的集合。 对于曲线来说，和上面的例子类似，不过曲线是二维的，它可以表示为f(x,y) = 0,于是，曲线的演化可以转化成曲面的演化，而曲面的演化导致了level = 0的曲线的演化。接下来，我们说的就是曲面的演化。 演化一个表面S，而不是一条曲线C，且我们用隐式轮廓法得到的轮廓的定义为这个表面S在高度h=0的所有点构成的集合。于是根据定义，水前曲线就是零水平集φ=0。如下图所示，是从一个演化的表面得到轮廓。以下是演化表面轮廓的过程。 可以看到，在初始时t=0,水平集的轮廓为一个矩形；在t=50的时候，轮廓由3个闭环开始合并为一个闭环，而在t=52时，轮廓结束了合并；在t=90时，轮廓开始分类，t=120时轮廓结束分裂。 水平集方程前面的部分都是直观地介绍一下大致原理，接下来就是玄学的数学理解过程。对于平面上的一个点来说，我们可以这样表示x = (x,y),那么点x属于一个随时间演化的曲线x(t)，而对于x(t)来说，它也会随时间变化，我们将x(t)随t的变化表示成一个新的函数：$\\phi(x(t),t)$,并且定义我们的轮廓就在$\\phi(x(t),t)$ = 0的平面上。 那么什么是$\\phi(x(t),t)$呢，事实上，任何符合$\\phi(x(t),t)$ = 0的曲线和我们的初始轮廓相同的$\\phi(x(t),t)$都可以。 在时刻t=0处，给定初始函数$\\phi$，根据运动方程∂s/∂t我们可以得到任意t时刻的s。对于此，利用链式法则，有： 把$\\frac{\\partial\\phi}{\\partial x}$记作$\\nabla \\phi$,$x_t$ 的方向由表面的法向量给定 ，因此$ x_t = F(x)\\vec{n},\\vec{n} = {\\nabla\\phi \\over{\\phi}}$ 上面的运动方程刻重写为： 最后一个方程定义了φ的运动。给定t=0时的φ以及它随时间演化的运动方程，我们可以通过演化初始函数 $\\phi(x,y,t = 0)$ 得知任何t时刻的 $\\phi(x,y,t)$, 样我们就回答了最初的问题，即我们知道了$\\phi $是什么。 这样我们就回答了最初的问题，即我们知道了$\\phi$是什么。 $\\phi $有个有趣的特征，就是我们可以用下式得到表面的曲率： 我们可以用它来控制平滑度。 说实话，没看懂，看懂了再写。 老翻译家了，这个资料太少了，YouTube上有讲解视频，但那英语真难顶。 参考资源 https://profs.etsmtl.ca/hlombaert/levelset/#fig:levelset-square https://www.cnblogs.com/hyb221512/p/9415995.html 水平集——那些我膜拜过的牛人2[链接实在太长] https://www.zhihu.com/question/22608763","link":"/%E6%B0%B4%E5%B9%B3%E9%9B%86%E7%AE%97%E6%B3%95/"},{"title":"计组-中央处理器","text":"CPU的功能 功能 说明 指令控制 产生下一条指令在内存中的地址、取指令 操作控制 将指令分解成一系列微操作控制信号，控制各部件完成指令所要求的动作 时序控制 对指令的各个微操作实施时间的定时，使它们能按时间先后顺序来执行 数据加工 算术运算、逻辑运算 中断处理 处理异常情况和特殊请求 其它 如总线处理 根据上表，我们能看到：CPU = 控制器 + 运算器 计算机指令控制过程 取指令的过程可用以下流程图表示： CPU的组成 内部主要部件 运算部件ALU 寄存器 控制部件（时序部件和微操作信号发生器） 中断控制逻辑 CPU数据通路 控制总线 数据总线 地址总线 ALUALU基本组成： 输入数据通过多路选择器来选择不同的数据或者是锁存器（寄存器），输出数据可通过移位器取出不同的结果。 寄存器 寄存器类型 说明 通用寄存器 存放原始数据和运算结果，用户可编程访问 专用寄存器 例如PC,IR，暂存器（用来暂存信息，用户不能直接访问，如源寄存器），状态寄存器PSW(用于指示CPU工作方式、算逻辑指令运算结果特征等) 用作主存接口的寄存器 例如地址寄存器AR(MRA)、数据寄存器DR(MDR) 控制单元CU控制单元主要包括： 时序部件 微操作信号发生器 时序部件一般包括： 脉冲源 启停控制逻辑 时序信号发生器 用于产生工作周期、节拍、脉冲等时间信号标志。 微操作信号是最基本的控制命令， 产生微操作的基本依据如下： 时序信号 指令代码（操作码，寻址方式，寄存器号等） 状态（CPU内部的PSW和外设的状态等） 外部请求（控制台请求、外部中断请求、DMA请求等） 根据微操作信号形成的方式，可以将控制分为 组合逻辑控制器；速度快，但电路复杂。 微程序控制器速度稍慢，但电路规整易扩充 CPU内部数据通路结构 单组内总线数据通路结构 多组内总线结构 CPU芯片主要技术参数 字长 内部工作频率 外部工作频率；内频=外频*倍频 前端总线频率（前端总线：连接内存显卡等，是CPU与外界交换数据的主要通路） 地址总线宽度（决定可访问的最大物理空间） 数据总线宽度 …… 时序控制方式与时序系统时序控制方式 同步控制方式 各项微操作都由固定的，统一的时序进行控制。 特点：控制方式简单，容易实现，但存在时间浪费 应用：CPU内部或设备内部 异步控制方式 各微操作按其需要选择不同的时间间隔，不受统一的时间约束；各微操作间的衔接与各部件间的信息交流采用应答方式。 特点：没有时间浪费，提高了效率，但控制复杂 应用：系统总线操作控制 准同步控制方式（总线上大部分采用该方法） 异步方式的同步化（只在节拍结束时查询异步应答信号） 联合控制方式 同步控制方式下的多级时序系统 时序层次划分 指令周期：从取值到指令结束所需时间 三级时序划分：工作周期（机器周期）、节拍（时钟周期）、节拍脉冲（工作脉冲、定时脉冲） 二级时序划分：节拍、节拍脉冲 工作周期与节拍的信号生成 每个工作周期都用一个触发器与之对应 在一条指令运行的任何时刻，只能处于一种工作周期，因此，有且只有一个触发器被置0。 T3用于切换不同的工作周期，T3节拍下降沿可切换工作周期。（该图红色标注有部分错误，不影响主要理解） 节拍信号发生器 以统一节拍法为例 通过时钟来变化环形移位寄存器内的数，实现T0-T3的循环变化。 指令的微操作序列这部分内容只要抓住：CPU取指令、计算、IO几个主干进行理解、实例化内容即可掌握。 模型机 硬件结构（简化PC）16位机 （1）总线：系统总线、内部总线；两者通过AR、 DR连接。 （2）控制器 （3）运算器 （4）寄存器 （5） 内存和I/O设备 注： 由PC向AR发送地址可分为两步：PC-&gt;IB;ARin.后一步不能忘。 ALU做减法运算，下面那个是被减数。 模型机指令系统及寻址方式 （1）指令系统 双操作数指令 双操作数指令的10-15位为操作码，8-9位不用，7位表示两操作数所在寄存器的源操作数和目的操作数顺序，4-6位对应一个操作数的寄存器寻址或寄存器间接寻址方式（8种情况）。3位是指令单/双字节指示，0-2说明另一个操作数的寻址方式（8种情况）。若双子节指示为1，则需一个额外的字存储偏移量等数据。 模型机的时序系统与控制方式 和上面提到的CPU的时序系统与控制方式差不多，这里的共组周期认为有5个，新增可插入DMA周期（DMAC）和可插入中断周期INTC。CPU内部采用同步控制，CPU与MM和I/O之间采用准同步。 16位模型机取指令过程及说明 第一步：将PC中的指令的地址发送到AR中。 第二步：CU发出读内存命令/MMRD，同时将AR中的指令地址送到MAR中；PC寄存器指针转到下一条指令的地址（16位模型机所以是PC+2）。 第三步：将在内存中读好的指令码传入DR中。 第四步：将DR中的指令码传入IR中。","link":"/%E8%AE%A1%E7%BB%84-%E4%B8%AD%E5%A4%AE%E5%A4%84%E7%90%86%E5%99%A8/"},{"title":"数据库_关系数据库设计理论","text":"关系规范中的函数依赖理论 数据依赖分类 说明 函数依赖 包括平凡函数依赖、非平凡函数依赖、完全函数依赖、部分函数依赖、传递函数依赖、等价 多值依赖 无 连接依赖 无 解决依赖的方式： ​ 利用规范化理论，对关系模型进行相应的分解，以消除这些异常。 函数依赖函数依赖的定义：$$若有一个关系模式R(A_1,A_2,…,A_n)，X和Y为\\{A_1,A_2,…,A_n}的子集，r是R中的任意具体关系，\\t_1,t_2是r中的任意两个元组。如果t_1[X]=t_2[X]\\可以推导出t_1[Y]=t_2[Y]，则称X函数决定Y或Y函数\\依赖于X，记作X → Y。$$最小函数依赖集： 定义： 如果F满足下列条件，则称F是最小的函数依赖集。 ​ ① F中每个函数的右边都只有一个属性。 ​ ② 对F中的任何函数依赖A→B，都不存在A的一个真子集C，使函数依赖C →B代替函数依赖A→B后得到和原来的F等价的一组依赖。 ​ ③ 从F中移出任何一个函数依赖都无法再得到和原来的F等价的一组函数依赖。 计算最小函数依赖的方法： 用分解法则。是F中的任何一个函数依赖右部仅含一个属性。 去掉多余的函数依赖。 去掉依赖左部多余属性。 计算最小函数依赖示例： 关系中的1 NF、2 NF、3 NF关系规范化的概念： ​ 关系规范化是一种形式化的技术，它利用主键和候选键以及属性之间的函数依赖来分析关系，这种技术包括一系列作用于单个关系的测试，一旦发现某关系未满足规范化要求，就分解该关系，直到满足规范化要求。 关系模式中的键 候选键：设K为R(U,F)中的属性或属性组，若 ，则K为R的候选键。（K为决定R中全部属性值的最小属性组）。 主键 全键：候选键为整个属性组。 主属性与非主属性： 在R(U,F)中，包含在任一候选键中的属性称为主属性，不包含在任一候选键中的属性称为非主属性。 外键：若R(U,F)的属性（组）X（X属于U）是另一个关系S的主键，则称X为R的外键。（X必须先被定义为S的主键）。 1 NF(最基本的范式) ​ 设R是一个关系模式。如果R的每个属性的值域，都是不可分的简单数据项的集合（即每个属性都不是多值属性也是不复合属性），则称R为第一范式关系模式，记做1 NF。即1 NF要求表中无重复值的列，或表中每一行列交叉处只有一个值。 2 NF 如果R(U,F) ∈1 NF，并且R中的每个非主属性都完全函数依赖于主键，则R(U,F) ∈2 NF 。 从以上定义可以看出，若某个第一范式关系的主键只由一个列组成，则这个关系就是第二范式关系。但如果某个第一范式关系的主键由多个属性列共同构成复合主键，并且存在非主属性对主键的部分函数依赖，则这个关系就不是第二范式关系。 用模式分解的办法可以将非第二范式关系分解为多个第二范式关系。去掉部分依赖关系的分解过程如下： ① 用组成主键的属性集合的每一个子集作为主键构成一个关系。 ​ ② 将依赖于这些主键的属性放置到相应的关系中。 ​ ③ 最后去掉只由主键的子集构成的关系。 3 NF 如果R(U,F) ∈2 NF，并且所有的非主属性都不传递依赖于主键，则R(U,F) ∈3 NF 。 关系数据库的设计目的是消除部分依赖和传递依赖，因为这些依赖会导致更新异常。第二范式和第三范式都不允许存在对主键的部分依赖和传递依赖，但这些定义并没有考虑对候选键的依赖问题。如果只考虑对主键的依赖关系，则在第三范式的关系中可能存在引起数据冗余的函数依赖。第三范式的这些不足导致了另一种更强范式的出现，即Boyce-Codd范式。 BC 范式（Boyce-Codd 范式）如果R(U,F) ∈1 NF，若X→Y且Y￠X时X必包含候选键，则R(U,F) ∈BCNF。 通俗地讲，当且仅当关系中每个函数依赖的决定因子都是候选键时，该范式即为Boyce-Codd范式。 3 NF和BCNF之间的区别在于对一个函数依赖A→B, 3 NF允许B是主键属性，而A不是候选键，而BCNF则要求在这个依赖中，A必须是候选键。因此BCNF也是3 NF，只是更加规范。大多数情况下， 3 NF关系都是BCNF的，只有在特殊情况下，才会发生违反BCNF的情况： ​ ① 关系中包含两个或更多的复合候选键； ​ ② 候选键有重叠，通常至少有一个重叠的属性。","link":"/%E6%95%B0%E6%95%B0%E6%8D%AE%E5%BA%93-%E5%85%B3%E7%B3%BB%E6%95%B0%E6%8D%AE%E5%BA%93%E8%AE%BE%E8%AE%A1%E7%90%86%E8%AE%BA/"},{"title":"互联网搜索引擎","text":"总线12345678graph TBA(文本预处理)--&gt;B(词典及检索)C(单个词项查询)--&gt;D(短语查询)D--&gt;E(查询-文档匹配评分)B--&gt;EE--&gt;F(聚类)H(相关反馈)--&gt;GF--&gt;G(文本分类) 文本预处理 预处理项 文本标记化 删除停用词 分词 词条归一化 词形还原 语言对搜索的影响 文本的预处理操作很多都依赖于特定的语言。例如，对于中文或日语而言，没有词与词之间的空格，对于阿拉伯语而言，它的阅读顺序从右到左，但遇到数字又从左到右。对不同语言的分词、标记化和其它预处理操作都需要针对性地做出适应。 停用词 一般文本中大约30%左右的内容都是停用词，即传达信息极少的那一类词，例如“的”，“是”，“我”，“嗯”，诸如此类，这些词语按道理来说性价比过低。但现在的趋势越来越偏离删除停用词的方向，因为在很多情形下，尤其是我们对精确搜索的需求，我们需要停用词来表示更精确的信息，例如歌名，短语，有关联的事务，在搜索它们的时候倘若忽略停用词，得到的结果可能就不尽人意。 归一化 对词语的标准化也是为了减少搜索的负担，对于英语来说，可能U.S.A和USA表达的意思在大部分情境下完全一样，搜索引擎没有必要将二者区分，而对于德语或者其他语言来说，可能会有音调符号、变音符，这些也需要处理，因为在大部分使用情景中，人们并不会标注变音符。对于同义词，比如car和automobile,它们表示的意思基本相同，所以当用户搜索car时，我们也需要查找对应的automobile的内容，对于那些只是有单复数变化，或者所有格变化的，我们也应该做同样的处理。而对于同音词（Soundex）和拼写错误(词独立校正法：编辑距离、k-grams;上下文敏感校正法)的情况，我们也需要做出相应的反应。你可能注意到了，这也要求对不同语言做到个性化处理，在英文和德语中，同一个字母组成的词语，意义却可能风牛马不相及。此外，归一化通常还包括将字母置为小写，将日期形式统一等等。 词干还原 词干还原的重要基础就是分词技术，英文中存在着大量的派生词，通过分词技术我们尽量将那些添加了后缀、前缀的词语都合并到一个词根项中（词形还原），减少搜索的负担。 短语查询在实际的搜索过程中，我们通常不会只用一个词语来搜索，我们有时会使用一个短语来查询。对于单词查询，我们只需要在文档中匹配相应的单词即可，对于有多个单词、单词之间还有联系的短语查询，有其他的方法来处理。 双词索引 将短语中的中的各个单词组合形成新的项，例如：在短语“stanford university palo alto”中，将“standford university”和“university palo”、“palo alto”添加到terms中，我们也可以更进一步，不仅仅只是组合临近的单词，而将每个可能组合成合理单词的组合添加到terms中。但这种方法有着伪正例和索引空间激增的问题（词典中词项数目增多），包含这些所有terms的文档未必真满足短语查询条件。§双词索引方法并不是一个标准的做法 (即倒排索引中一般不会全部采用双词索引方法)，但是可以和其他方法混合使用。 带位置信息索引 倒排记录表中，对每个term在每篇文档中的每个位置(偏移或者单词序号)进行存储:$$&lt;term:出现term文档的篇数\\doc1:位置1，位置2、、位置3\\doc2:位置1，位置2、、位置3\\doc1:位置1，位置2、、位置3\\…………………….\\&gt;$$对于输入的短语查询，需要在文档的层次上进行迭代(不同位置上)合并。不仅仅是简单合并，还要考虑位置匹配。可以使用临近查询，限制某些词项之间的前后距离不大于某值来匹配，而这对双词项并不适用。 词典及容错式检索 词典是指存储词项词汇表的数据结构，词项词汇表(Term vocabulary): 指的是具体数据。对于每个词项，需要存储词项频率和指向倒排记录表的指针，若词项信息采用定长方式存储，则存储图示如下： 为快速定位词项，我们通常使用哈希表和二叉树（B树）两种数据结构来查询： 哈希表： 优点: 在哈希表中的定位速度快于树中的定位速度 查询时间是常数 缺点： 没办法处理词项的微小变形 (resume vs. résumé) 不支持前缀搜索 (比如所有以automat开头的词项) 如果词汇表不断增大，需要定期对所有词项重新哈希 Levenshtein distance 两个字符串s1和s2编辑距离是指从 s1 转换成s2所需要的最短的基本操作数目，基本操作包括插入、替换、删除和交换。 除以上内容外，还有轮排索引、k-gram 索引的内容，但并非重点,不做详细介绍。 轮排索引过程 将查询进行旋转，将通配符旋转到右部 同以往一样查找B-树 问题：相对于通常的B-树，轮排树的空间要大4倍以上 (经验值) 查询-文档匹配评分 Jaccard 系数$$JACCARD(A,B) = \\frac{A\\cap B}{A\\cup B}$$ 不足： 不考虑词项频率 ，即词项在文档中的出现次数 罕见词比高频词的信息量更大，Jaccard系数没有考虑这个信息 没有仔细考虑文档的长度因素 词项频率 词项t的词项频率 $$tf_{t,d}$$ 是指t 在d中出现的次数,但原始的$$tf_{t,d}$$不太合适，因为相关度并不和频率成正比关系，所以我们引入对数词频$$w_td= \\begin{cases}1+\\log_{10}tf_{t,d}, &amp;\\mbox{if } tf_{t,d&gt;0}\\0, &amp;\\mbox{otherwise}\\end{cases}$$除词项频率tf之外，我们还想利用词项在整个文档集中的频率进行权重和评分计算,因为罕见词项比常见词所蕴含的信息更多，某篇包含该词项的文档很可能相关，于是，我们希望罕见词项将有较高权重。为此，我们引入文档频率(Document frequency, df)，$$idf_t=log_{10}\\frac{N}{df_t}$$综上，词项t在文档d中的权重我们可以采用下下式计算：$$w_{t,d}=1+\\log_{10}tf_{t,d}\\times log_{10}\\frac{N}{df_t}$$基于以上的内容跟，我们可以将每篇文档表示成一个基于tfidf权重的实值向量 ∈ R|V|.，于是，我们有一个 |V|维实值空间，空间的每一维都对应词，文档都是该空间下的一个点或者向量，对于Web搜索引擎，这个向量空间会上千万维，对每个向量来说又非常稀疏，大部分都是0。 我们对查询做同以上的同样处理，将查询表示成与文档同一维空间的向量，我们就可以通过比较查询向量和文档向量之间的距离来比较二者的相似度。距离的计算我们不采用欧氏距离，因为它对向量长度很敏感 ，我们可以通过比较夹角来比较相似度，这里的夹角的意义大概等同于查询和文档中的词项分布情况，分布情况越接近，夹角就越小。由于cosin函数在[0,pi]上是单调递减函数，我们可以比较两向量的cos值来比较夹角。 回转归一化 但是余弦归一化更倾向于短文档，即对短文档产生的归一化因子太大，而平均而言对长文档产生的归一化银子太小。我们可以通过找到一个平衡点，对余弦归一化操作进行线性调整使短文档相似度降低，长文档相似度增大来去除原来余弦归一化偏向短文档的问题。 精确TOP K检索及其加速办法 目标：从文档集的所有文档中找出个里查询最近的文档。 一般步骤：将每个文档按评分（余弦相似度）从高到低排序，取前K个结果。 加速策略: 加快余弦相似度的计算 一般在高维空间下，没有很高效的计算余弦的方法。如果查询很短，假设每个查询词项只出现一次，即查询词项无权重，可以通过省略查询向量归一化的方法轻微简化余弦相似度计算方法。 不对所有评分结果排序 通堆方法选出TOP K,堆的构建需要2 J次操作，选出前K个结果，需要2log J步，这里J表示文档总个数。 不计算所有文档的得分 提前终止计算 找一个文档集合A,K&lt;|A|&lt;&lt;N,用A中的TOP K结果代替整个文档集的TOP K结果 仅考虑高idf的词项，低idf代表着出现的次数多，蕴含的信息也少，只考虑高idf词项可以有效减少计算文档数量。 选择出现多次查询词项地文档 胜者表：选取每个词项对应的权重最高的r篇文档作为胜者表，取每个词项的胜者表的并集中的TOP K作为文档集的TOP K结果。 …………………………………………… IR评价 IR 评价指标 效率（时间开销、空间开销、响应速度） 效果（准确率、召回率、F值） 覆盖率 访问量 更新速度 …… 省略关于召回率、准确率的说明。 基于调和平均计算出来的F值，可以看成是平滑的最小值函数，无论是P还是R，如果非常低，结果上都应该表现出相应的惩罚，而使用平均值或者精确率都不能达到这样的效果。 由于和查询相关的文档在文档集中占少数，即使对查询不做任何结果返回，精确率也能很高。 聚类 分类 分割式（Partitional） 分层式(Hierarchical) Definition: The process of grouping a set of objects into classes of similar objects. Success Criteria: Documents within a cluster should be similar Documents from different clusters should be dissimilar 以上两者的评判都取决与presentation document的选择和相似度的计算方法。 以上是比较通用的判断聚类是否成功的方法，还有通过一个聚类内部纯度的方法来判断，这里就不赘述。 聚类假设：在同一个聚类中的文档，就需求信息的相关性而言，它们的行为类似。$$\\longrightarrow$$ 所以，若要提高搜索返回结果的相关性，我们可以从以下两各方面入手： 我们需要在语料库中提前将文本聚类好 返回查询匹配文档所在聚类的其它所有文档 聚类在信息检索里的应用： 分析和导航整个语料库；提供了一个更好的用户接口，可以实现不打字也能搜索。 提高搜索结果的召回率。 对搜索结果有更好的导航 基于聚类的检索速度更快。 以下是聚类检索的例子，通过下图能对以上所说的应用有更直观的理解。 ISSUES FOR CLUSTERING 选出聚类的代表文档 评判文档之间相似度的方式 选择聚类的个数 固定值 由具体数据决定 文档相似度计量 文档相似度更多体现在文档的语义、内容上的相似性，计量与一相似性的一种可行方法是词量统计相似性。将每个文档视作一个向量，我们计量文档间的相似度即是计算向量间的距离，我们在表达的时候虽然常说的是“欧氏距离”，但在实际应用中，我们将会用到的是“余弦距离”。 分割式聚类我们将文档只做一次聚类，将文档一次分割为多个聚类，但是这会带来聚类个数的选定问题。分层聚类有两种，一种自上而下，一种至下而上，前者会迭代地聚类，将聚类结果再次聚类得到更精确的类，后者反之。 几种判断聚类间距离的策略： 本博客不对聚类做更多说明，在应用中可使用Hard-Cluster或者Soft-Cluster,前者每个文档只属于一个聚类，后者每个文档可以属于多个聚类。在课程设计中我们使用的是K-MEANS算法，在实现中需要注意的是K-MEANS算法中不同的聚类起始点的选择对结果会造成很大的影响。在此也不对K-MEANS算法做具体介绍。 文本分类文本分类的任务描述： 已知文本T的描述D和已知分类集合C，试图通过函数$$\\gamma(D)$$将文本T分类到某个C的某个类中。 监督分类的任务描述： 已知文本T的描述D、已知分类集合C、训练集&lt;d,c&gt;$$\\in X\\times C$$，试图训练出分类器$$\\gamma :X\\rightarrow C$$和通过函数$$\\gamma(D)$$将文本T分类到某个C的某个类中。 分类方法 手工分类：直接；精度高；不易于处理大文件；成本高。 自动分类 统计/概率方法 本次总结中还有一些方面并未提及，包括摘要的选择，相关反馈还有分类方法中的朴素贝叶斯和文本分类评价。","link":"/%E4%BA%92%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E/"},{"title":"计组-指令系统","text":"指令格式​ 指令是机器语言的一个语句，由操作码字段和地址码字段构成。指令的长度取决于操作码的长度和操作数的地址及长度。若在一个指令系统中，所有的指令长度都相等，则称该指令系统为定长指令字结构，若各种指令的长度随指令功能而异，就称该指令系统为变长指令字结构。 ​ 从地址结构的角度出发，可以介绍以下五种指令结构，以下出现的地址皆为显地址，若是按照实现约定，用隐含的方式给出的地址称为隐地址。 四地址指令：四个地址分别为操作数1地址、操作数2地址、结果存放地址、下一条指令地址 三地址指令：相比四地址指令，少了“下一条指令地址”一项，其交给PC(Program Counter)给出。 二地址指令：相比三地址指令，少了“结果存放地址”一项，将操作数1地址视为目的操作数地址，操作数2地址视为源操作数地址，计算结果保存在目的操作数地址中。 一地址指令：只有一个操作数地址，另一个操作数隐含给出，在累加寄存器中。 零地址指令：零地址的算术逻辑类指令是用在堆栈计算机中的，草鱼算术逻辑运算的两个操作数隐含地从堆栈顶部弹出。 指令的操作码分为规整性编码（定长编码）和非规整性编码，最常用的非规整型编码方式是扩展操作码法，扩展操作码法的组合可以有很多种，但有以下两点要注意： 不允许短码是长码的前缀。 各条指令的操作码一定不能重复，且各类指令的格式安排应该统一。 寻址技术寻址技术包括编址方式和寻址方式。通常计算机中需要编制的有CPU中的通用寄存器，主存储器和输入输出设备三种，编址单位常用的有字编址、字节编址和位编址，这是按编址单位区分的，编址单位（最小寻址单位）与主存容量决定了指令格式中每个地址码的位数，容量越大，编制单位越小，地址码位数自然越长。 寻址可以分为指令寻址和数据寻址，前者寻找下一条指令的地址，后者寻找操作数的地址。指令寻址又可分为顺序寻址和跳跃寻址。顺序寻址可通过PC自动加一获得下一条指令的地址，跳跃寻址需要程序转移类指令来实现，跳跃寻址的转移地址形成方式有三种，分别为：直接（绝对）、相对和间接寻址，这与数据寻址方式中对应，不过是寻找的对象不同而已。以。下以方式较多的数据寻址来解释各种寻址方式： 立即寻址。指令中操作码后面的字段不是地址，而是操作数本身。 寄存器寻址。数据存放在寄存器中，指令中操作码后面给出通用寄存器的编号。 直接寻址。数据存放在主存中，指令中操作码后面给出操作数的有效地址，此时形式地址即为有效地址。 间接寻址。可分为一次间接寻址和多次间接寻址，扩大了寻址范围，可将主存单元作为程序的地址指针，但也降低了取操作数的速度。对于多次间接寻址来说，应给设有间址标志位，来区分当前主存单元存放的是地址还是操作数。 寄存器间接寻址。操作数放在主存中，指令中操作码后面给出存有操作数地址的通用寄存器的编号。 变址寻址。将指令中的形式地址与变址寄存器$R_x$中的内容相加得到操作数的有效地址。在具有变址寻址的指令中，除去操作码和形式地址之外，还应具有变址寻址标志，当具有多个变址寄存器时，还应指明具体的变址寄存器。$$S = ((R_x) + A)$$ 基址寻址。将指令中操作码后面给出的位移量D与基址寄存器$R_b$中的内容相加，得到操作数的有效地址。在逻辑甚至硬件实现上都和变址寻址即为相似。但是二者的主要不同在于：变址寻址中指令提供基准值（固定的），变址寄存器提供修改量（可变的）；而基址寻址中，基址寄存器提供基准值，指令中提供位移量。前者面向用户，后者面向系统。 相对寻址。相对寻址是基址寻址的一种变通，由PC提供基准地址。 页面寻址。页面寻址可分为以下3类： 基页寻址。又称零页寻址，此时相当于直接寻址。 当前页寻址。取PC中的高位部分内容，得到当前指令所处页面，和指令中的形式地址拼接，得到操作数地址。 页寄存器寻址。页面地址取自页寄存器。 除以上常用的9中基本的寻址方式外，还有3种由这些寻址方式变型或组合而来的寻址方式。 自增型寄存器间址和自减型寄存器间址。这实际上是寄存器间接寻址的变型，对于自增寻址来说，它的寻址操作逻辑为：$$1.\\space EA = (R_i)\\2.\\space (Ri) = (R_i) + d\\$$记作:EA = (R_i)+。自减寻址类似，不过有一点格外注意，自增寻址是先操作再修改$((R_i)+)$,而自减寻址是先修改再操作$(-(R_i))$,修改后的内容才作为有效地址。 扩展变址方式。把变址和间址两种寻址方式组合，按操作顺序分为前变址和后变址两种寻址方式。以下是前变址寻址方式逻辑。 $$EA = ((R_x)+A)\\ S = (((R_x)+A))$$ 以下是后变址寻址方式逻辑：$$EA = (R_x) + (A)\\S = ((R_x) + (A))$$​ 后变址先将指令中的地址码变址，再与变址值运算得到有效地址。 基址变址寻址。最为灵活，有效地址由指令中的位移量，基址寄存器中的值，变址寄存器中的值相加的来，即 $$EA = (R_b) + (R_x) + D$$","link":"/%E8%AE%A1%E7%BB%84-%E6%8C%87%E4%BB%A4%E7%B3%BB%E7%BB%9F/"},{"title":"计组-存储系统和结构","text":"存储系统的组成存储系统和存储器是两个不同的概念。 存储器的分类 按存储器在计算机中的作用分类 高速缓冲存储器（Cache） 主存储器 辅助存储器 按存储方式分类 随机存取存储器（RAM） 只读存储器（ROM） 顺序存取存储器（SAM） 直接存取存储器（DAM） 按存储介质分 磁芯存储器 半导体存储器 磁表面存储器 光存储器 按信息的可保存性分类 易失性存储器 非易失性存储器 存储器的层次结构为了解决存储容量、存储速度和价格之间的矛盾，通常会把多种存储器按一定体系结构组织起来，构成一个完成的存储系统。一般来说，越靠近CPU的存储器价格越高、速度越快、容量越小。 由Cache、主存、辅存构成的三级存储系统可分为两个层次： Cache-主存存储层次（Cache 存储系统） 主存-辅存存储系统（虚拟存储系统） 前者是为了解决主存速度不足，后者是为了解决主存容量不足。 主存储器的组织主存通常由存储体、地址译码驱动电路（包含译码器和驱动电路两部分）、I/O和读写电路组成。 存储单元是CPU对主存可访问操作的最小存储单位。 大端方案：字地址等于最高有效字节地址 小端方案：字地址等于最低有效字节地址 大端方案会将数字的高位（指数字的高位而非物理存储单元编号的高位）置于低地址，小端方案反之。 数据在主存中的存放主要有三种方式： 所有数据紧接着上一个存放 一个存储字只存放一个数据，无论数据的长度 边界对齐的数据存放方法。对于存取字长为64位的机器而言，64位数据的起始地址的最末3个二进制位必须为000（8的倍数，机器按字节编址，信息在主存中存放的起始地址必须是该信息宽度（字节数）的整数倍），32位数据的起始地址的最末3个二进制位必须为00，以此类推。 RAM和ROMRAM分为SRAM和DRAM，前者存取速度快但集成度低，功耗大，一般用来组成高速缓冲存储器和小容量主存系统，后者集成度高功耗小但速度慢。 DRAM没有外加电源和只靠栅极电容上的电荷保持信息，而电荷会逐渐释放，为了维持DRAM的存储信息，需要对栅极电容补充电荷，这就是刷新，刷新的间隔由栅极电容上的电荷泄放速度来决定的，一般选定为2ms或4ms甚至更大，刷新通常以存储体矩阵中的一行为单位进行。常见的刷新方式有以下三种： 集中式刷新。在允许的最大刷新间隔内，安排特定的一段连续时间对目标存储区域全部刷新一遍。 分散式刷新，把刷新操作分散到每个存储周期中。 异步刷新方式。是以上两种方式的结合，将分散式刷新的单位变为了行，集中式刷新的单位也变成了行。减小了死区时间和刷新次数。 RAM芯片通过地址线（单向），数据线（双向）和控制线与外部链接，控制线主要有片选控制线（$\\overline {CE}或\\overline {CS}$）和读写控制线($\\overline {WE}或\\overline{OE} / \\overline{WE}$)。RAM芯片中地址译码分为单译码和双译码两种，其中单译码又称字选法，结构简单但外围电路多成本昂贵，双译码方式又称重合法，通常就是把K位地址线分为接近相等的两段，一段用于水平方向做X地址线，一段做垂直方向Y地址线。 ROM具有非易失性，工作时只能读出而不能写入。可以分为以下几类： 掩模式ROM 一次可编程ROM 可擦除编程ROM,又分为紫外线擦除和电擦除 闪速存储器 主存储器的连接与控制要组成主存，首先要将芯片连接起来，将芯片组合起来的方法有位扩展法、字扩展法和同时扩展法。 位扩展：加大字长，即增加数据线，例如用64K×1的芯片组成64K×8的芯片。 字扩展：仅在字数方向扩展而位数不变，即增加地址线，方法是增加数据线和译码器。 同时扩展法：即以上两种方法的结合。 CPU要实现对存储单元的访问，需要先进行片选，再进行字选，片选信号大多由CPU送出的高位地址译码或直接连接产生，片内的字选是由低位地址线完成。片选信号的产生可细分为线选法、全译码法和部分译码法。 线选法：用非片内寻址外的高位地址线直接连接（或经反相器）分别接至哥哥存储芯片的片选段，当某地址线信息为“0”时（只能有一位有效，这也决定了片选法的地址空间是相互隔离的），就选中对应的存储芯片。这种方法仅适用于连接存储芯片较少的场合。 全译码法：将除片内地址之外的全部高位地址线都作为地址译码器的输入，译码器的输出作为各芯片的片选信号。全译码法的优点是每组芯片的地址范围是唯一确定并且连续的，不会产生重叠的存储区，但对译码电路要求较高。 部分译码法：将除片内地址之外的部分高位地址线都作为地址译码器的输入，若只有4片芯片，则只需要用到两位地址即可，其它的地址不起作用，这样就产生了地址重叠区域。可以令未用到的高位地址全为0，这样确定的存储器地址为基本地址。 主存与CPU的硬连接线有三组：地址总线（AB）、数据总线（DB）、控制总线（CB）。主存与CPU之间的接口为存储器地址寄存器（MAR）和存储器地址寄存器（MDR），这二者从功能上看属于主存，但小型计算机中常放在CPU内。 CPU对主存进行读写操作的流程大概如下： CPU在地址总线上给出地址信号 发出相应的读写信号 数据总线上交换信息 对于“读”操作来说，流程如下： 地址→MAR→AB CPU将地址信号送至地址总线；Read CPU发读命令；Wait for MFC 等待存储器工作完成信号；M(MAR)→DB→MDR 读出信息经数据总线送至CPU 对于“写”操作来说，流程如下： 地址→MAR→AB CPU将地址信号送至地址总线；数据→MDR→DB CPU将要写入的数据送至数据总线；Write CPU发写命令；Wait for MFC 等待存储器工作完成信号。 CPU和主存的速度存在差异，两者间的速度匹配有两种方式： 同步存储器读取（CPU、主存有统一的时钟,这种情况下不需要主存工作完成信号） 异步存储器读取（CPU、主存没有统一的时钟） 主存与CPU需要频繁地交换信息，为了检测和校正和存储过程中的错误，主存中常设有差错校验电路，现代PC中主存的容错能力被分为基本的三级： 无奇偶校验 奇偶校验 ECC(Error Checking and Correcting,ECC) 目前，主存的存取速度成为了计算机系统的瓶颈，除了通过高速元件来提高访问速度外（FPM DRAM，DDR SDRAM等），也可以采用多个存储器并行工作，并且用交叉访问技术来提高存储器访问速度。 并行访问技术：多个并行工作的存储器共有一套寄存器和译码电路 交叉访问存储器：多个容量相同的存储模块具有各自的寄存器和译码电路，它们既可以并行工作，又能交叉工作。 相联存储器：根据内容（或部分内容），查找其地址及与之相关的内容。 高速缓冲存储器高速缓存的原理： 程序的局部性原理：时间局部性和空间局部性，前者是指一个被访问的存储单元很可能在将来再次被访问，后者指一个被访问的存储单元邻近的存储单元也很可能在将来被访问。 Cache的基本结构 Cache的读操作很简单，CPU发出读请求时，若Cache命中，则直接对Cache进行读操作，否则访问主存并将该块信息一次从主存调入Cache内，若此时Cache已满，则须根据替换算法将这个块替换Cache中原来某块的信息。 Cache保存的只是主存中的部分副本，Cache中的内容需要与主存内容保持一致，当CPU发出写请求时，若Cache命中，需要进行一定的处理，处理的方法有写直达法和写回法，若未命中就直接将信息写入主存，并有不按写分配法和按写分配法两种处理方法。 不按写分配法：将要写的信息直接写入主存 按写分配法：将信息写入主存后将该块信息从主存读入Cache 写直达法：把数据同时写入主存和Cache 写回法：只把数据写入Cache并用标志将该块注明，等该块替换回到主存时才写回主存。 在Cache中通过地址映像把主存地址空间映像到Cache地址空间，有三种方法： 全相联映像：主存中任意一个块可以映像到Cache中任何一个块的位置。冲突率低、空间利用率高但成本高且地址变换速度慢。 直接映像：把主存分成若干个区，每个区的大小与Cache大小相同，主存地址分为三部分：区号，块号和块内地址。主存中的每一个块只能被放置到Cache中唯一的一个指定位置，若这个位置已有内容，则产生冲突，原来的块被无条件替换出去。成本低易实现，地址变换速度快，且没有替换算法的问题，但冲突率高，利用率低。 组相联映像：主存按Cache的组数目划分区的块数，主存中每个区的第i块都可以映射到Cache第i组中的任意一块，主存地址分为三部分：区号，块号和块内地址，Cache地址也分为三部分：组号、组内块号和块内地址。即组间采取直接映像，组内采取全相联映像。优缺点介于以上二者。 三种替换算法： 随机算法：简单根据一个随机数，选择一块换掉。 先进先出算法（FIFO）：将最先进入Cache的作为被替换的块。实现简单，系统开销小，但可能将需要经常使用的块替换掉。 近期最少使用算法（LRU）：将近期最少使用的块替换，实现复杂，系统开销大。 虚拟存储器虚拟存储器由主存储器和联机工作的辅助存储器共同组成，这两个存储器在硬件和软件系统的共同管理下工作，将主存或辅存的地址空间统一编址，形成一个庞大的存储空间。 用户编程的地址称为虚地址或逻辑地址，实际的主存单元地址称为实地址或物理地址，虚地址比实地址大得多。虚拟存储器需要提供动态的地址映像机制，将逻辑地址转换为对应的物理地址，常见的方法有： 页式虚拟存储器：以页为基本单位的虚拟存储器称为页式虚拟存储器，主存空间和虚存空间都划分成若干个大小相等的页，主存即实存的页称为实页，虚存的页称为虚页。程序的地址分为两部分：高位字段的虚页号和低位字段的页内地址，虚地址到实地址间的变换通过页表来实现。页表记录着程序的虚页调入主存时被安排在主存中的位置，页表中的每一行记录了某个虚页对应的若干信息，包括虚页号、装入位和实页号等。 页表的建立很方便，调入调出容易实现，但当存储空间较大时，页表占用的空间很大，效率降低。页不是逻辑上独立的实体，使程序额处理、保护和共享比较困难。 段式虚拟存储器：段式虚拟存储器的“段”是按程序的逻辑结构划分的，各个段的长度因程序而异，为将程序的虚地址转换为实地址，需要段表，段表中的每一行记录了某个段对应的若干信息，包括段号、装入位、段起点和段长等。段表一般驻留在主存中。编程使用的虚地址包含两部分：段号和段内地址，CPU根据虚地址访存时，将段号与段表的起始位置相加，得到访问段表的行位置，若根据装入位判断该段已经调入主存，则将该段在主存中的起始位置加上段内地址，得到对应的主存实地址。 断食虚拟存储器具有逻辑独立性，易于程序的编译、管理、修理和保护，也便于程序的多道共享，但段的长短不一，起终点不定，为主存空间分配带来了麻烦，容易在段间形成不能利用的零头，造成浪费。 段页式虚拟存储器： 将程序按逻辑结构分段，每段划分为若干个大小相同的页，主存空间也划分为若干大小相同的页，虚存与实存之间以页为基本传输单位，每个程序对应一个段表，每段对应一个页表。CPU访问时，虚地址包括:段号、段内页号，页内地址三部分。段的长度必须是页长的整数倍，段的起点必须是某一页的起点。","link":"/%E8%AE%A1%E7%BB%84-%E5%AD%98%E5%82%A8%E7%B3%BB%E7%BB%9F%E5%92%8C%E7%BB%93%E6%9E%84/"}],"tags":[{"name":"CV","slug":"CV","link":"/tags/CV/"},{"name":"Image","slug":"Image","link":"/tags/Image/"},{"name":"数据库","slug":"数据库","link":"/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"学习","slug":"学习","link":"/tags/%E5%AD%A6%E4%B9%A0/"},{"name":"算法","slug":"算法","link":"/tags/%E7%AE%97%E6%B3%95/"},{"name":"C++","slug":"C","link":"/tags/C/"},{"name":"图像分割","slug":"图像分割","link":"/tags/%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2/"},{"name":"计算机组成原理","slug":"计算机组成原理","link":"/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86/"},{"name":"搜索引擎","slug":"搜索引擎","link":"/tags/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E/"}],"categories":[{"name":"Vision","slug":"Vision","link":"/categories/Vision/"},{"name":"Study","slug":"Study","link":"/categories/Study/"},{"name":"Algorithm","slug":"Algorithm","link":"/categories/Algorithm/"},{"name":"CPlus","slug":"CPlus","link":"/categories/CPlus/"},{"name":"计算机组成原理","slug":"Study/计算机组成原理","link":"/categories/Study/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86/"},{"name":"数据库","slug":"Study/数据库","link":"/categories/Study/%E6%95%B0%E6%8D%AE%E5%BA%93/"}]}